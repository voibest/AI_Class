{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this part is to process chinese wikipedia documents to simplified version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zh_wiki_00 has been processed! std_zh_wiki_00 has been created!\n",
      "zh_wiki_01 has been processed! std_zh_wiki_01 has been created!\n",
      "zh_wiki_02 has been processed! std_zh_wiki_02 has been created!\n"
     ]
    }
   ],
   "source": [
    "def replace_func(file_path, file_name):\n",
    "    p1 = re.compile(r'-\\{.*?(zh-hans|zh-cn):([^;]*?)(;.*?)?\\}-')\n",
    "    p2 = re.compile(r'[（\\(][，；。？！\\s]*[）\\)]')\n",
    "    p3 = re.compile(r'[「『]')\n",
    "    p4 = re.compile(r'[」』]')\n",
    "    outfile = codecs.open(file_path + 'std_' + file_name, 'w', 'utf-8')\n",
    "    with codecs.open(file_path + file_name, 'r', 'utf-8') as myfile:\n",
    "        for line in myfile:\n",
    "            line = p1.sub(r'\\2', line)\n",
    "            line = p2.sub(r'', line)\n",
    "            line = p3.sub(r'\"', line)\n",
    "            line = p4.sub(r'\"', line)\n",
    "            outfile.write(line)\n",
    "    outfile.close()\n",
    "            \n",
    "    \n",
    "def run():\n",
    "    file_path = 'C:\\\\Users\\\\margaret\\\\OneDrive\\\\Documents\\\\AI\\\\Class_2\\\\extracted\\\\AA\\\\'\n",
    "    file_names = ['zh_wiki_00', 'zh_wiki_01', 'zh_wiki_02']\n",
    "    for file_name in file_names:\n",
    "        replace_func(file_path, file_name)\n",
    "        print(\"{} has been processed! std_{} has been created!\".format(file_name, file_name))\n",
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read in ONE text file, my pc can't process all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in(file_path, file_name):\n",
    "    ret = codecs.open(file_path+file_name, 'r', 'utf-8').readlines()\n",
    "    return \"\".join(ret)\n",
    "\n",
    "def read_in_batch():\n",
    "    file_path = 'C:\\\\Users\\\\margaret\\\\OneDrive\\\\Documents\\\\AI\\\\Class_2\\\\extracted\\\\AA\\\\'\n",
    "    #file_names = ['std_zh_wiki_00', 'std_zh_wiki_01', 'std_zh_wiki_02']\n",
    "    file_names = ['std_zh_wiki_00']\n",
    "    ret = [read_in(file_path, file_name) for file_name in file_names]\n",
    "    return \"\".join(ret)\n",
    "\n",
    "wiki_data = read_in_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<doc id=\"13\" url=\"https://zh.wikipedia.org/wiki?curid=13\" title=\"数学\">\\r\\n数学\\r\\n\\r\\n数学是利用符号语言研究数量、结构、变化以及空间等概念的一门学科，从某种角度看属于形式科学的一种。数学透过抽象化和逻辑推理的使用，由计数、计算、量度和对物体形状及运动的观察而产生。数学家们拓展这些概念，为了公式化新的猜想以及从选定的公理及定义中建立'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_data[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"改编的漫画。日本\"快乐快乐月刊\"从2006年10月号开始连载。台湾由青文出版社代理出版漫画单行本。\\r\\n\\r\\n居住在神奥地方的少年小晴，挑战神话的故事。\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n</doc>\\r\\n<doc id=\"1020264\" url=\"https://zh.wikipedia.org/wiki?curid=1020264\" title=\"安城车站\">\\r\\n安城车站\\r\\n\\r\\n安城车站是一由东海旅客铁道（JR东海）所经营的铁路车站，位于日本爱知县安城市御幸本町，是东海道本线沿线的车站，也是所在地安城市的主车站。站内设有绿窗口与各种相关的服务设施。\\r\\n\\r\\n安城车站的设置可以追溯到1891年时，当时安城还只是个村级的行政区域。1939年时碧海电气铁道的货物支线（之后的名铁安城支线）曾连结至附近并设置有货运专用的\"新安城车站\"（但与今日名铁名古屋本线上的新安城车站是不相同的两个车站）。新安城在1951年起开始经营客运服务而改名为\"安城\"，而与隶属于日本国铁的安城车站合并成为转运车站。但安城支线已于1961年时废线。\\r\\n\\r\\n岛式月台1面2线与侧式月台2面2线的地面车站。\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n</doc>\\r\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_data[-500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_rn(strings):\n",
    "    p2 = re.compile(r'\\r|\\n|\\t')\n",
    "    return p2.sub(r'', strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<doc id=\"13\" url=\"https://zh.wikipedia.org/wiki?curid=13\" title=\"数学\">数学数学是利用符号语言研究数量、结构、变化以及空间等概念的一门'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_data = delete_rn(wiki_data)\n",
    "wiki_data[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get 60ish documents from wiki. Clean them, keep the ones that have more than 1000 words\n",
    "# Results: get 48 documents with different titles: 数学， 设计， 物理，上海市等\n",
    "# 清理文档，去除特殊字符等等，文件保存成 dictionary, 'key = title, value = essay content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<doc id=\"13\" url=\"https://zh.wikipedia.org/wiki?curid=13\" title=\"数学\">数学数学是利用符号语言研究数量、结构、变化以及空间等概念的一门'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = wiki_data[:400000].split(\"</doc>\")\n",
    "documents[0][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#keep documents that have more than 1000 words\n",
    "documents = list(filter(lambda x: len(x) > 1000, documents))\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_tokenize(doc):\n",
    "    return re.findall(r'.*title=\"(.+)\">(.+)', doc)[0]\n",
    "def process_documents(documents):\n",
    "    return [get_info_tokenize(doc) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_info = process_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_info(infos):\n",
    "    doc_info = {}\n",
    "    for key, content in infos:\n",
    "        doc_info[key] = content\n",
    "    return doc_info\n",
    "doc_info = get_doc_info(doc_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['数学', '哲学', '文学', '历史', '计算机科学', '民族', '戏剧', '电影', '音乐', '经济学', '政治学', '法学', '社会学', '物理学', '天文学', '力学', '化学', '地理学', '地质学', '气象学', '生物学', '心理学', '中医学', '海洋学', '水文学', '测绘学', '农业', '中华人民共和国', '克利斯登·奈加特', 'Self', 'Linux内核', '林纳斯·托瓦兹', '理查德·斯托曼', '孙中山', '操作系统', 'Linux', 'GNU计划', '自由软件运动', '诺贝尔奖', '植物学', '生命', 'Wiki', '计算机程序', '中国历史', '亳州市', '上海市', '高德纳', '中国'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_info.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'数学数学是利用符号语言研究数量、结构、变化以及空间等概念的一门学科，从某种角度看属于形式科学的一种。数学透过抽象化和逻辑推理的使用，由计数、计算、量度和对物体形状及运动的观察而产生。数学家们拓展这些概'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_info['数学'][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(strings):\n",
    "    p1 = re.compile(r'<.*>')\n",
    "    strings = p1.sub(r'', strings)\n",
    "    return \"\".join(re.findall(r'[\\w\\d]+', strings))\n",
    "\n",
    "def doc_info_tokenize2(doc_info):\n",
    "    return {key:tokenize(content) for key, content in doc_info.items()}\n",
    "\n",
    "doc_info = doc_info_tokenize2(doc_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'数学数学是利用符号语言研究数量结构变化以及空间等概念的一门学科从某种角度看属于形式科学的一种数学透过抽象化和逻辑推理的使用由计数计算量度和对物体形状及运动的观察而产生数学家们拓展这些概念为了公式化新的'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_info['数学'][:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build 1 gram model & 2 gram model for each document\n",
    "# 计算raw frequency, 以及 word frequency in documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('的', 313),\n",
       " ('学', 228),\n",
       " ('数', 217),\n",
       " ('一', 77),\n",
       " ('有', 75),\n",
       " ('在', 70),\n",
       " ('为', 66),\n",
       " ('理', 64),\n",
       " ('是', 60),\n",
       " ('中', 48)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "doc_one_gram_counts = {key: Counter(content) for key, content in doc_info.items()}\n",
    "doc_one_gram_counts['数学'].most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('数学', 146),\n",
       " ('科学', 43),\n",
       " ('研究', 33),\n",
       " ('领域', 32),\n",
       " ('问题', 29),\n",
       " ('学的', 24),\n",
       " ('学家', 24),\n",
       " ('的数', 24),\n",
       " ('许多', 19),\n",
       " ('理论', 19)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_two_gram(strings):\n",
    "    return Counter([strings[i:i+2] for i in range(len(strings)-1)])\n",
    "doc_two_gram_counts = {key: get_two_gram(content) for key, content in doc_info.items()}\n",
    "doc_two_gram_counts['数学'].most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get documents frequency\n",
    "def get_doc_frq(doc_info):\n",
    "    return Counter([c for key, content in doc_info.items() for c in content])\n",
    "doc_frq_one_gram = get_doc_frq(doc_one_gram_counts)\n",
    "doc_frq_two_gram = get_doc_frq(doc_two_gram_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('是', 48), ('以', 48), ('的', 48), ('一', 48), ('和', 48)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_frq_one_gram.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('孪', 1),\n",
       " ('迦', 1),\n",
       " ('牟', 1),\n",
       " ('耆', 1),\n",
       " ('笩', 1),\n",
       " ('駄', 1),\n",
       " ('翅', 1),\n",
       " ('旃', 1),\n",
       " ('诘', 1),\n",
       " ('翱', 1)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(doc_frq_one_gram.items(), key = lambda x: x[1])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('一个', 46), ('以及', 45), ('的一', 45), ('研究', 43), ('使用', 43)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_frq_two_gram.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate raw term frequency function : get_freq(word_counts) 课上讲的内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get term frequency for n_gram model\n",
    "def get_term_freq(count):\n",
    "    all_occurance = sum(count.values())\n",
    "    min_occurance = min(count.values())\n",
    "    def get_freq_helper(item):\n",
    "        return count[item] * 1.0 / all_occurance if item in count else min_occurance / all_occurance\n",
    "    return get_freq_helper\n",
    "    \n",
    "word_frq_one_gram = get_term_freq(doc_one_gram_counts['数学'])\n",
    "word_frq_two_gram = get_term_freq(doc_two_gram_counts['数学'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caclualte idf-tf frequency function: get_tf_idf(raw_docs, word_doc_counts, word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get idf for n_gram model\n",
    "import numpy as np\n",
    "def get_tf_idf(doc_info, word_doc_counts, word_counts, get_doc_freq, get_term_freq):\n",
    "    N = len(doc_info)\n",
    "    doc_frq = get_doc_frq(word_doc_counts)\n",
    "    max_counts = max(word_counts.values())\n",
    "    def get_tf_idf_helper(item):\n",
    "        idf = np.log(N / (doc_frq[item]))\n",
    "        #tf = 0.5 + 0.5 * get_term_freq(item) / max_counts\n",
    "        tf = get_term_freq(item)\n",
    "        return idf * tf\n",
    "    return get_tf_idf_helper\n",
    "\n",
    "doc_one_gram_counts_math = doc_one_gram_counts['数学']\n",
    "word_freq_one_gram = get_term_freq(doc_one_gram_counts_math)\n",
    "doc_two_gram_counts_math = doc_two_gram_counts['数学']\n",
    "word_freq_two_gram = get_term_freq(doc_two_gram_counts_math)\n",
    "one_gram_tf_idf = get_tf_idf(doc_info, doc_one_gram_counts, doc_one_gram_counts_math, get_doc_frq, word_frq_one_gram)\n",
    "two_gram_tf_idf = get_tf_idf(doc_info, doc_two_gram_counts, doc_two_gram_counts_math, get_doc_frq, word_freq_two_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('的', 0.055212559534309404),\n",
       " ('学', 0.040218733462691836),\n",
       " ('数', 0.03827835597107074),\n",
       " ('一', 0.01358264244134768),\n",
       " ('有', 0.013229846533780208),\n",
       " ('在', 0.012347856764861527),\n",
       " ('为', 0.011642264949726583),\n",
       " ('理', 0.011289469042159111),\n",
       " ('是', 0.010583877227024167),\n",
       " ('中', 0.008467101781619333)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_BoW_trd = {key: word_freq_one_gram(key) for (key, item) in doc_one_gram_counts_math.items()}\n",
    "sorted(math_BoW_trd.items(), key = lambda x:x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('猜', 0.004401710795582648),\n",
       " ('逻', 0.0033785455275046326),\n",
       " ('数', 0.0033306524619420783),\n",
       " ('谨', 0.0033012830966869856),\n",
       " ('奖', 0.0028724839190826484),\n",
       " ('亦', 0.0023359891179427312),\n",
       " ('函', 0.0020377042108159224),\n",
       " ('辑', 0.002007601620321167),\n",
       " ('问', 0.0018386218611412505),\n",
       " ('题', 0.0017761285122265531)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_BoW_tf_idf = {key: one_gram_tf_idf(key) for (key, item) in doc_one_gram_counts_math.items()}\n",
    "sorted(math_BoW_tf_idf.items(), key = lambda x:x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build one_gram & two_gram models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from operator import mul\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "class N_gram_model:\n",
    "    def __init__(self, doc_info, method = \"tf\", n = 1):\n",
    "        self.doc_info = doc_info\n",
    "        self.method = method\n",
    "        self.n = n\n",
    "        self.N = len(self.doc_info)\n",
    "        self.doc_frq = Counter([c for key, content in self.doc_info.items() for c in content])\n",
    "        #self.model_func stores \"title\":[func_one_gram_prob(), func_two_gram_prob()]\n",
    "        self.model_func = {}\n",
    "        self.two_word_dictionary = {}\n",
    "        assert(self.method == \"tf\" or self.method == \"tf-idf\"), \"Method has to be either 'tf' or 'tf-idf'\"\n",
    "        assert(self.n == 1 or self.n == 2),  \"Can only do 1 or 2 gram model\"\n",
    "    \n",
    "    #get word raw frequency\n",
    "    def get_counts(self, strings, n_gram):\n",
    "        return Counter([strings[i:i+n_gram] for i in range(len(strings)-n_gram+1)])\n",
    "        \n",
    "    def get_tf(self, counts):\n",
    "        #count : counts of words in one doc\n",
    "        all_occurance = sum(counts.values())\n",
    "        min_occurance = min(counts.values())\n",
    "        def get_tf_helper(item):\n",
    "            return counts[item] * 1.0 / all_occurance if item in counts else min_occurance / all_occurance\n",
    "        return get_tf_helper\n",
    "\n",
    "    #get word tf-idf frequency\n",
    "    def get_tf_idf(self, counts):\n",
    "        #count : counts of words in one doc\n",
    "        all_occurance = sum(counts.values())\n",
    "        min_occurance = min(counts.values())\n",
    "        def get_tf_idf_helper(item):\n",
    "            return np.log(self.N / (self.doc_frq[item] + 1)) * counts[item] * 1.0 / all_occurance if item in counts else np.log(self.N) * min_occurance / all_occurance\n",
    "        return get_tf_idf_helper\n",
    "    \n",
    "    def one_gram_prob(self, key, string): \n",
    "        assert(self.model_func), \"Train Model first!!\"\n",
    "        #for char in string:\n",
    "        #    print(char, self.model_func[key][0](char))\n",
    "        #return [self.model_func[key][0](char) for char in string]\n",
    "        return reduce(mul, [5e2 * self.model_func[key][0](char) for char in string])\n",
    "    \n",
    "    def two_gram_prob(self, key, string):\n",
    "        assert(self.model_func and self.two_word_dictionary), \"Train Model first!!\"\n",
    "        string = \".\" + string\n",
    "        funcs = self.model_func[key]\n",
    "        dictionary = self.two_word_dictionary[key]\n",
    "        probs = [5e2 * funcs[1](string[i-1:i+1]) / funcs[0](string[i-1]) if string[i-1:i+1] in dictionary else 5e2 * funcs[0](string[i]) for i in range(1, len(string))]\n",
    "        return reduce(mul, probs)\n",
    "    \n",
    "    def train_n_gram_model(self):\n",
    "        for key, content in self.doc_info.items():\n",
    "            if self.n == 1:\n",
    "                one_gram_counts = self.get_counts(content, 1)\n",
    "                if self.method == \"tf\":\n",
    "                    one_gram_BoW_prob = self.get_tf(one_gram_counts)\n",
    "                else:\n",
    "                    one_gram_BoW_prob = self.get_tf_idf(one_gram_counts)\n",
    "                self.model_func[key] = [one_gram_BoW_prob]\n",
    "            else:\n",
    "                one_gram_counts = self.get_counts(content, 1)\n",
    "                two_gram_counts = self.get_counts(content, 2)\n",
    "                if self.method == \"tf\":\n",
    "                    one_gram_BoW_prob = self.get_tf(one_gram_counts)\n",
    "                    two_gram_BoW_prob = self.get_tf(two_gram_counts)\n",
    "                else:\n",
    "                    one_gram_BoW_prob = self.get_tf_idf(one_gram_counts)\n",
    "                    two_gram_BoW_prob = self.get_tf_idf(two_gram_counts)\n",
    "                self.model_func[key] = [one_gram_BoW_prob, two_gram_BoW_prob]\n",
    "                self.two_word_dictionary[key] = set(two_gram_counts.keys())\n",
    "        return\n",
    "    \n",
    "    def compute_sentence_prob(self, sentence):\n",
    "        res = {}\n",
    "        for key in self.doc_info:\n",
    "            if self.n == 1:\n",
    "                res[key] = self.one_gram_prob(key, sentence)\n",
    "            else:\n",
    "                res[key] = self.two_gram_prob(key, sentence)\n",
    "        return sorted(res.items(), key=lambda x:x[1], reverse=True) \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['数学', '哲学', '文学', '历史', '计算机科学', '民族', '戏剧', '电影', '音乐', '经济学', '政治学', '法学', '社会学', '物理学', '天文学', '力学', '化学', '地理学', '地质学', '气象学', '生物学', '心理学', '中医学', '海洋学', '水文学', '测绘学', '农业', '中华人民共和国', '克利斯登·奈加特', 'Self', 'Linux内核', '林纳斯·托瓦兹', '理查德·斯托曼', '孙中山', '操作系统', 'Linux', 'GNU计划', '自由软件运动', '诺贝尔奖', '植物学', '生命', 'Wiki', '计算机程序', '中国历史', '亳州市', '上海市', '高德纳', '中国'])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_info.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = {\"几何\":\"\"\"几何学是数学的一个基础分支，主要研究形状、大小、图形的相对位置等空间区域关系以及空间形式的度量。 \n",
    "\"\"\",\n",
    "\"电脑\": \"\"\"\n",
    "电子计算机，亦称电脑，计算机是一种利用数字电子技术，根据一系列指令指示其自动执行任意算术或逻辑操作串行的设备。\n",
    "通用计算机因有能遵循被称为“程序”的一般操作集的能力而使得它们能够执行极其广泛的任务。 \n",
    "\"\"\",\n",
    "\"北京\":\"\"\"北京市，通称北京\n",
    "简称“京”，是中华人民共和国首都、直辖市、中国国家中心城市和京津冀城市群的重要组成部分，是中国的政治、文化、科技创新和国际交往中心，\n",
    "是世界第三大人口最多的城市和人口最多的首都，具有重要的国际影响力。\n",
    "\"\"\",\n",
    "\"森林\":\"\"\"\n",
    "森林，是一个高密度树木的区域（或历史上，森林是一个为狩猎而留出的荒地），涵盖大约9.4％的地球表面（或30％的占总土地面积[1]）。\n",
    "森林覆盖着全球面积的9.4%，全球陆地面积的30%（在工业化前约占全球面积的15.6%，全球陆地面积的50%），\n",
    "森林对二氧化碳下降、动物群落、调节水文湍流和巩固土壤起着重要作用，是地球生物圈中最重要的生境之一。 \"\"\",\n",
    "\"这个杀手不太冷\":\"\"\"\n",
    "《这个杀手不太冷》（原题：Léon，美国上映片名：The Professional）是一部1994年的电影，由法国导演卢贝松编剧及执导，也是他首部往好莱坞发展拍摄的电影。由让·雷诺、加里·奥德曼及娜塔莉·波特曼主演。 \n",
    "本片的背景和主要拍摄地是纽约市。 本片上映当时的版本片长为110分钟，但另有一133分钟的版本。\n",
    "该加长版本正式名称为“国际版”（International Version），不过只在日本上映，之后并以影像软件方式发售。\n",
    "但导演卢贝松表示，他自己比较喜欢称之为“加长版”（Long Version）。\"\"\",\n",
    "\"钢琴\":\"\"\"\n",
    "钢琴（英语：Piano），是西洋古典音乐中的一种键盘乐器，前身为古钢琴（Fortepiano），\n",
    "普遍用于独奏、重奏、伴奏等演出，用于作曲和排练音乐十分方便。弹奏者通过按下键盘上的琴键，\n",
    "牵动钢琴里面包着绒毡的小木槌，继而敲击钢丝弦发出声音。 \n",
    "钢琴音域宽广，音色宏亮、清脆，富于变化，表现力很强。独奏时，可演奏各种气势磅礡、宽广、抒情的音乐，\n",
    "亦可演奏欢快、灵巧、技巧性很高的华彩乐段，在乐队中则可发挥巨大的作用，还经常作为伴奏乐器使用。\n",
    "钢琴因其丰富的乐理表达能力，被称作“乐器之王”\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = {key:tokenize(content) for (key, content) in strings.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'几何学是数学的一个基础分支主要研究形状大小图形的相对位置等空间区域关系以及空间形式的度量'"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings['几何']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample text from title: 几何\n",
      "\t\t [('力学', 112158652350350.23), ('数学', 63518490045.03928), ('测绘学', 39580825298.49413), ('气象学', 14142629856.670567), ('地理学', 6550971683.179622)] \n",
      "\n",
      "sample text from title: 电脑\n",
      "\t\t [('计算机程序', 3.4102464875571024e+19), ('计算机科学', 87920.1338058645), ('力学', 318.5487434090102), ('GNU计划', 0.07871791551306145), ('测绘学', 0.016904449493206773)] \n",
      "\n",
      "sample text from title: 北京\n",
      "\t\t [('中华人民共和国', 1.671164703344819e+16), ('亳州市', 669589203930714.5), ('上海市', 151223035552.04083), ('中国', 1233806269.2252407), ('测绘学', 26235194.496515937)] \n",
      "\n",
      "sample text from title: 森林\n",
      "\t\t [('水文学', 1.1628578950737727e+26), ('测绘学', 4.095147716389282e+18), ('地质学', 837401414110910.0), ('海洋学', 31971349650.255875), ('亳州市', 2017.9020250487458)] \n",
      "\n",
      "sample text from title: 这个杀手不太冷\n",
      "\t\t [('GNU计划', 5.3188755732631384e+16), ('Self', 4434707792.041121), ('林纳斯·托瓦兹', 1024.8735555331589), ('高德纳', 0.5919378520378796), ('地质学', 0.0016527042086695858)] \n",
      "\n",
      "sample text from title: 钢琴\n",
      "\t\t [('音乐', 2.5910584855752096e-05), ('GNU计划', 1.1143709243372694e-19), ('力学', 2.6461720877772003e-21), ('地质学', 1.563434511120092e-22), ('水文学', 4.9598484586556395e-23)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "nlp_n_gram = N_gram_model(doc_info, \"tf\", 1)\n",
    "nlp_n_gram.train_n_gram_model()\n",
    "#nlp_n_gram.compute_sentence_prob(strings['几何'])\n",
    "#nlp_n_gram.one_gram_prob(\"数学\", strings[\"几何\"])\n",
    "for key, test_string in strings.items():\n",
    "    print(\"sample text from title: {}\".format(key))\n",
    "    print(\"\\t\\t\", nlp_n_gram.compute_sentence_prob(test_string)[:5], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample text from title: 几何\n",
      "\t\t [('气象学', 1.2924325390522114e+30), ('数学', 1.8570420915837098e+28), ('地理学', 1.9152580843485678e+27), ('地质学', 8.337843684119354e+25), ('海洋学', 3.5136570015895245e+25)] \n",
      "\n",
      "sample text from title: 电脑\n",
      "\t\t [('计算机程序', 4.492789585182262e+56), ('力学', 8.866534165977386e+47), ('GNU计划', 6.066298057162059e+42), ('自由软件运动', 6.715654642426369e+37), ('水文学', 3.948665385628269e+37)] \n",
      "\n",
      "sample text from title: 北京\n",
      "\t\t [('亳州市', 1.6224912427968427e+61), ('中华人民共和国', 2.7357187261123905e+55), ('海洋学', 1.7650593423249242e+53), ('诺贝尔奖', 8.56583057173378e+52), ('上海市', 1.1592555444579174e+51)] \n",
      "\n",
      "sample text from title: 森林\n",
      "\t\t [('亳州市', 3.2097476289304295e+74), ('力学', 1.4077368314806533e+66), ('GNU计划', 5.7532663931784045e+63), ('Self', 1.5936281859760379e+63), ('高德纳', 1.52349798804173e+55)] \n",
      "\n",
      "sample text from title: 这个杀手不太冷\n",
      "\t\t [('GNU计划', 1.2155934649994818e+124), ('Self', 9.824724483154136e+117), ('林纳斯·托瓦兹', 2.136351944930437e+99), ('高德纳', 8.772819131381074e+93), ('克利斯登·奈加特', 2.869699494199198e+87)] \n",
      "\n",
      "sample text from title: 钢琴\n",
      "\t\t [('地质学', 1.0877816140063712e+83), ('Self', 5.48925238561774e+81), ('力学', 2.9262844173295604e+80), ('气象学', 2.61170253722577e+71), ('计算机程序', 3.1014699241601633e+66)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "nlp_n_gram = N_gram_model(doc_info, \"tf-idf\", 1)\n",
    "nlp_n_gram.train_n_gram_model()\n",
    "#nlp_n_gram.compute_sentence_prob(strings['几何'])\n",
    "#nlp_n_gram.one_gram_prob(\"数学\", strings[\"几何\"])\n",
    "for key, test_string in strings.items():\n",
    "    print(\"sample text from title: {}\".format(key))\n",
    "    print(\"\\t\\t\", nlp_n_gram.compute_sentence_prob(test_string)[:5], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample text from title: 几何\n",
      "\t\t [('地理学', 6.1013840155416e+48), ('力学', 1.598589317268936e+48), ('数学', 4.785331310826532e+47), ('物理学', 5.161202919129473e+46), ('天文学', 2.725284946269499e+39)] \n",
      "\n",
      "sample text from title: 电脑\n",
      "\t\t [('计算机科学', 1.0831873016992042e+86), ('操作系统', 3.707377202270224e+75), ('计算机程序', 6.6076829135887916e+69), ('Linux', 1.951618339920632e+60), ('Linux内核', 7.551812350806555e+51)] \n",
      "\n",
      "sample text from title: 北京\n",
      "\t\t [('中华人民共和国', 2.6371380263548054e+117), ('上海市', 5.277615984504488e+101), ('中国', 7.125426944858817e+92), ('中国历史', 1.8134552327883945e+78), ('法学', 4.024268723660244e+59)] \n",
      "\n",
      "sample text from title: 森林\n",
      "\t\t [('中华人民共和国', 2.45650367912491e+103), ('上海市', 3.1427602762048367e+87), ('农业', 5.672401317075411e+78), ('水文学', 1.761329607518112e+78), ('海洋学', 5.67423327195216e+56)] \n",
      "\n",
      "sample text from title: 这个杀手不太冷\n",
      "\t\t [('电影', 1.8750015419261672e+95), ('GNU计划', 4.704778663442274e+75), ('Self', 2.4718254977494934e+71), ('林纳斯·托瓦兹', 1.3347410001506632e+68), ('高德纳', 3.983451739076663e+66)] \n",
      "\n",
      "sample text from title: 钢琴\n",
      "\t\t [('音乐', 2.161921206817515e+78), ('电影', 3.171148284889155e+26), ('文学', 6945.513953425961), ('GNU计划', 1.1571209132444657e-05), ('水文学', 6.083917846797308e-06)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "nlp_n_gram = N_gram_model(doc_info, \"tf\", 2)\n",
    "nlp_n_gram.train_n_gram_model()\n",
    "#nlp_n_gram.compute_sentence_prob(strings['几何'])\n",
    "#nlp_n_gram.one_gram_prob(\"数学\", strings[\"几何\"])\n",
    "for key, test_string in strings.items():\n",
    "    print(\"sample text from title: {}\".format(key))\n",
    "    print(\"\\t\\t\", nlp_n_gram.compute_sentence_prob(test_string)[:5], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample text from title: 几何\n",
      "\t\t [('地理学', 3.917160134028129e+60), ('数学', 5.126275148679928e+58), ('物理学', 6.367928850373905e+57), ('气象学', 4.5464787049106396e+51), ('天文学', 4.517418315097945e+51)] \n",
      "\n",
      "sample text from title: 电脑\n",
      "\t\t [('计算机程序', 4.120040138273438e+103), ('理查德·斯托曼', 1.421364376263598e+84), ('Linux内核', 2.8545315101151776e+83), ('音乐', 8.520764613539757e+71), ('心理学', 4.692267132984587e+69)] \n",
      "\n",
      "sample text from title: 北京\n",
      "\t\t [('中华人民共和国', 1.1067130054891673e+137), ('上海市', 1.581058353458977e+123), ('中国', 7.923134007846337e+109), ('法学', 4.257030772797124e+89), ('农业', 5.608490015477225e+80)] \n",
      "\n",
      "sample text from title: 森林\n",
      "\t\t [('水文学', 7.080875881426757e+136), ('上海市', 5.726615913241839e+126), ('地质学', 1.5004126578541441e+109), ('植物学', 5.971710557506913e+103), ('亳州市', 1.674123558358179e+90)] \n",
      "\n",
      "sample text from title: 这个杀手不太冷\n",
      "\t\t [('GNU计划', 1.4233535235826996e+171), ('电影', 8.318403914422438e+165), ('Self', 4.274838615347681e+163), ('林纳斯·托瓦兹', 2.4306848646294504e+145), ('理查德·斯托曼', 5.934624797882745e+140)] \n",
      "\n",
      "sample text from title: 钢琴\n",
      "\t\t [('音乐', 5.116556478160844e+149), ('电影', 2.0504368134478286e+99), ('水文学', 1.3177866030504345e+98), ('Self', 4.047809860035379e+95), ('地质学', 1.2513864972422048e+93)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "nlp_n_gram = N_gram_model(doc_info, \"tf-idf\", 2)\n",
    "nlp_n_gram.train_n_gram_model()\n",
    "#nlp_n_gram.compute_sentence_prob(strings['几何'])\n",
    "#nlp_n_gram.one_gram_prob(\"数学\", strings[\"几何\"])\n",
    "for key, test_string in strings.items():\n",
    "    print(\"sample text from title: {}\".format(key))\n",
    "    print(\"\\t\\t\", nlp_n_gram.compute_sentence_prob(test_string)[:5], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
